{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846f944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a76d5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 168 images belonging to 3 classes.\n",
      "Found 36 images belonging to 3 classes.\n",
      "Found 36 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Data Generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batchSize = 16\n",
    "size = 224\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"data/train\",\n",
    "    target_size=(size, size),\n",
    "    batch_size=batchSize,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    \"data/validation\",\n",
    "    target_size=(size, size),\n",
    "    batch_size=batchSize,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    \"data/test\",\n",
    "    target_size=(size, size),\n",
    "    batch_size=batchSize,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a98c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c02c6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(size, size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c6ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "\n",
    "#size = 128\n",
    "\n",
    "base_model = MobileNet(input_shape=(size, size, 3), weights='imagenet', include_top=False, alpha=0.5)\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "smaller_model = tf.keras.Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c67f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200bfe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 6s 362ms/step - loss: 0.8044 - accuracy: 0.6190 - val_loss: 0.5868 - val_accuracy: 0.6944\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 273ms/step - loss: 0.5081 - accuracy: 0.8214 - val_loss: 0.5005 - val_accuracy: 0.8333\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 274ms/step - loss: 0.4220 - accuracy: 0.7619 - val_loss: 0.4222 - val_accuracy: 0.8056\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 0.3613 - accuracy: 0.8333 - val_loss: 0.3792 - val_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.3079 - accuracy: 0.8988 - val_loss: 0.3485 - val_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 0.2685 - accuracy: 0.9226 - val_loss: 0.3203 - val_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 282ms/step - loss: 0.2822 - accuracy: 0.8690 - val_loss: 0.3377 - val_accuracy: 0.8611\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.2377 - accuracy: 0.9226 - val_loss: 0.2984 - val_accuracy: 0.9167\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 0.2290 - accuracy: 0.9226 - val_loss: 0.2791 - val_accuracy: 0.9167\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 282ms/step - loss: 0.2171 - accuracy: 0.9345 - val_loss: 0.2790 - val_accuracy: 0.9167\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 0.2260 - accuracy: 0.9107 - val_loss: 0.2561 - val_accuracy: 0.9444\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 283ms/step - loss: 0.2037 - accuracy: 0.9167 - val_loss: 0.2799 - val_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 0.2194 - accuracy: 0.9226 - val_loss: 0.2370 - val_accuracy: 0.9167\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.1814 - accuracy: 0.9167 - val_loss: 0.2404 - val_accuracy: 0.9167\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.1681 - accuracy: 0.9286 - val_loss: 0.2352 - val_accuracy: 0.9167\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 277ms/step - loss: 0.1605 - accuracy: 0.9583 - val_loss: 0.2248 - val_accuracy: 0.9167\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.1669 - accuracy: 0.9405 - val_loss: 0.2245 - val_accuracy: 0.9167\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 0.1527 - accuracy: 0.9583 - val_loss: 0.2230 - val_accuracy: 0.9167\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 0.1619 - accuracy: 0.9405 - val_loss: 0.2559 - val_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 0.1754 - accuracy: 0.9405 - val_loss: 0.2192 - val_accuracy: 0.9167\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3267 - accuracy: 0.8611\n",
      "Test Loss: 0.3267, Test Accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_set,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_steps=len(validation_set)\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_set)\n",
    "print(\"Test Loss: {:.4f}, Test Accuracy: {:.4f}\".format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37089743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Keras model as an H5 file\n",
    "model.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for _ in range(100):  # You can adjust the number of samples used here\n",
    "        # Get a single batch of data\n",
    "        x, _ = next(validation_set)\n",
    "        # Yield the data as a 1-item list containing a numpy array\n",
    "        yield [x.astype(\"float32\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e02cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained Keras model\n",
    "model = tf.keras.models.load_model(\"trained_mobilenetv1_128x128.h5\")\n",
    "\n",
    "# Set up the converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "# Perform quantization\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "# Save the quantized TensorFlow Lite model\n",
    "with open(\"trained_model_quantized.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quantized_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
